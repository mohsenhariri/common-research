| Model                | Vocab Size | Max Position Embeddings | Hidden Size | #Layers | #Heads | Activation Function | Torch Dtype | #Params (Est.) | #Params      |
| -------------------- | ---------- | ----------------------- | ----------- | ------- | ------ | ------------------- | ----------- | -------------- | ------------ |
| Qwen2.5-Math-72B-it  | 152064     | 4096                    | 8192        | 80      | 64     | silu                | bfloat16    | 72.71B         | 72706203648  |
| Recurrentgemma-9B-it | 256000     | N/A                     | 4096        | 38      | 16     | N/A                 | bfloat16    | 8.58B          | 8579977216   |
| Gemma2-27B-it        | 256000     | 8192                    | 4608        | 46      | 32     | gelu_pytorch_tanh   | bfloat16    | 27.23B         | 27227128320  |
| Gpt2-Medium          | 50257      | N/A                     | N/A         | N/A     | N/A    | N/A                 | None        | 354823.17K     | 354823168    |
| Mistral0.1-7B        | 32000      | 32768                   | 4096        | 32      | 32     | silu                | bfloat16    | 7.24B          | 7241732096   |
| Llama2-7B            | 32000      | 4096                    | 4096        | 32      | 32     | silu                | float16     | 6.74B          | 6738415616   |
| Llama2-Chat-7B       | 32000      | 4096                    | 4096        | 32      | 32     | silu                | float16     | 6.74B          | 6738415616   |
| Qwen2.5-72B-it       | 152064     | 32768                   | 8192        | 80      | 64     | silu                | bfloat16    | 72.71B         | 72706203648  |
| Llama3.2-3B-it       | 128256     | 131072                  | 3072        | 28      | 24     | silu                | bfloat16    | 3.21B          | 3212749824   |
| Llama3.1-8B          | 128256     | 131072                  | 4096        | 32      | 32     | silu                | bfloat16    | 8.03B          | 8030261248   |
| Qwen2.5-72B          | 152064     | 131072                  | 8192        | 80      | 64     | silu                | bfloat16    | 72.71B         | 72706203648  |
| Llama3-70B           | 128256     | 8192                    | 8192        | 80      | 64     | silu                | bfloat16    | 70.55B         | 70553706496  |
| Llama3-70B-it        | 128256     | 8192                    | 8192        | 80      | 64     | silu                | bfloat16    | 70.55B         | 70553706496  |
| Llama3.1-405B-it     | 128256     | 131072                  | 16384       | 126     | 128    | silu                | bfloat16    | 405.85B        | 405853388800 |
| Mistral2411-Large-it | 32768      | 131072                  | 12288       | 88      | 96     | silu                | None        | 122.61B        | 122610069504 |
| Gemma2-9B-it         | 256000     | 8192                    | 3584        | 42      | 16     | gelu_pytorch_tanh   | bfloat16    | 9.24B          | 9241705984   |
| Gemma2-27B           | 256000     | 8192                    | 4608        | 46      | 32     | gelu_pytorch_tanh   | float32     | 27.23B         | 27227128320  |
| Phi3-Medium-128K-it  | 32064      | 131072                  | 5120        | 40      | 40     | silu                | bfloat16    | 13.96B         | 13960238080  |
| Llama2-70B           | 32000      | 4096                    | 8192        | 80      | 64     | silu                | float16     | 68.98B         | 68976648192  |
| Llama3.2-1B-it       | 128256     | 131072                  | 2048        | 16      | 32     | silu                | bfloat16    | 1.24B          | 1235814400   |
| Llama3.1-8B-it       | 128256     | 131072                  | 4096        | 32      | 32     | silu                | bfloat16    | 8.03B          | 8030261248   |
| Qwen2.5-Math-7B-it   | 152064     | 4096                    | 3584        | 28      | 28     | silu                | bfloat16    | 7.62B          | 7615616512   |
| Gpt2-Large           | 50257      | N/A                     | N/A         | N/A     | N/A    | N/A                 | None        | 774030.08K     | 774030080    |
| Qwen2.5-Math-1.5B-it | 151936     | 4096                    | 1536        | 28      | 12     | silu                | bfloat16    | 1.54B          | 1543714304   |
| Mistral0.3-7B        | 32768      | 32768                   | 4096        | 32      | 32     | silu                | bfloat16    | 7.25B          | 7248023552   |
| Llama2-Chat-70B      | 32000      | 4096                    | 8192        | 80      | 64     | silu                | float16     | 68.98B         | 68976648192  |
| Gpt2-Xl              | 50257      | N/A                     | N/A         | N/A     | N/A    | N/A                 | None        | 1.56B          | 1557611200   |
| Ministral2410-8B-it  | 131072     | 32768                   | 4096        | 36      | 32     | silu                | bfloat16    | 8.02B          | 8019808256   |
| Llama3-8B            | 128256     | 8192                    | 4096        | 32      | 32     | silu                | bfloat16    | 8.03B          | 8030261248   |
| Qwen2.5-14B          | 152064     | 131072                  | 5120        | 48      | 40     | silu                | bfloat16    | 14.77B         | 14770033664  |
| Mistral0.3-7B-it     | 32768      | 32768                   | 4096        | 32      | 32     | silu                | bfloat16    | 7.25B          | 7248023552   |
| Qwen2.5-7B-it        | 152064     | 32768                   | 3584        | 28      | 28     | silu                | bfloat16    | 7.62B          | 7615616512   |
| Llama3.3-70B-it      | 128256     | 131072                  | 8192        | 80      | 64     | silu                | bfloat16    | 70.55B         | 70553706496  |
| Qwen2.5-1.5B         | 151936     | 131072                  | 1536        | 28      | 12     | silu                | bfloat16    | 1.54B          | 1543714304   |
| Recurrentgemma-2B-it | 256000     | N/A                     | 2560        | 26      | 10     | N/A                 | bfloat16    | 2.68B          | 2682862080   |
| Llama3-8B-it         | 128256     | 8192                    | 4096        | 32      | 32     | silu                | bfloat16    | 8.03B          | 8030261248   |
| Llama3.1-70B         | 128256     | 131072                  | 8192        | 80      | 64     | silu                | bfloat16    | 70.55B         | 70553706496  |
| Qwen2.5-7B           | 152064     | 131072                  | 3584        | 28      | 28     | silu                | bfloat16    | 7.62B          | 7615616512   |
| Gemma2-9B            | 256000     | 8192                    | 3584        | 42      | 16     | gelu_pytorch_tanh   | float32     | 9.24B          | 9241705984   |
| Qwen2.5-14B-it       | 152064     | 32768                   | 5120        | 48      | 40     | silu                | bfloat16    | 14.77B         | 14770033664  |
| Gpt2                 | 50257      | N/A                     | N/A         | N/A     | N/A    | N/A                 | None        | 124439.81K     | 124439808    |
| Phi3-Mini-128K-it    | 32064      | 131072                  | 3072        | 32      | 32     | silu                | bfloat16    | 3.82B          | 3821079552   |
| Qwen2.5-Math-72B     | 152064     | 4096                    | 8192        | 80      | 64     | silu                | bfloat16    | 72.71B         | 72706203648  |
| Recurrentgemma-2B    | 256000     | N/A                     | 2560        | 26      | 10     | N/A                 | float32     | 2.68B          | 2682862080   |
| Recurrentgemma-9B    | 256000     | N/A                     | 4096        | 38      | 16     | N/A                 | bfloat16    | 8.58B          | 8579977216   |
| Llama3.1-70B-it      | 128256     | 131072                  | 8192        | 80      | 64     | silu                | bfloat16    | 70.55B         | 70553706496  |
| Phi3.5-Mini-it       | 32064      | 131072                  | 3072        | 32      | 32     | silu                | bfloat16    | 3.82B          | 3821079552   |
| Gemma2-2B-it         | 256000     | 8192                    | 2304        | 26      | 8      | gelu_pytorch_tanh   | bfloat16    | 2.61B          | 2614341888   |
| Llama2-13B           | 32000      | 4096                    | 5120        | 40      | 40     | silu                | float16     | 13.02B         | 13015864320  |
| Gemma2-2B            | 256000     | 8192                    | 2304        | 26      | 8      | gelu_pytorch_tanh   | float32     | 2.61B          | 2614341888   |
| Mathstral0.1-7B      | 32768      | 32768                   | 4096        | 32      | 32     | silu                | float32     | 7.25B          | 7248023552   |
| Llama3.2-1B          | 128256     | 131072                  | 2048        | 16      | 32     | silu                | bfloat16    | 1.24B          | 1235814400   |
| Qwen2.5-Math-1.5B    | 151936     | 4096                    | 1536        | 28      | 12     | silu                | bfloat16    | 1.54B          | 1543714304   |
| Llama3.2-3B          | 128256     | 131072                  | 3072        | 28      | 24     | silu                | bfloat16    | 3.21B          | 3212749824   |
| Llama2-Chat-13B      | 32000      | 4096                    | 5120        | 40      | 40     | silu                | float16     | 13.02B         | 13015864320  |
| Memotron3.1-it       | 128256     | 131072                  | 8192        | 80      | 64     | silu                | bfloat16    | 70.55B         | 70553706496  |
| Qwen2.5-1.5B-it      | 151936     | 32768                   | 1536        | 28      | 12     | silu                | bfloat16    | 1.54B          | 1543714304   |